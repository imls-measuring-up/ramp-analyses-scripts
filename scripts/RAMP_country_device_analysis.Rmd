---
title: "RAMP Country-Device Analyses"
author: "Minh Pham, Nikolaus Parulian, Jon Wheeler"
date: "3/2/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

GitHub repository URL: <https://github.com/imls-measuring-up/ramp-analyses-scripts>

## R Markdown

These are the calculations used to generate the tables and figures in [the manuscript].

File paths for data file imports are relative to the structure of the GitHub repository. Update file paths as needed. If this notebook was downloaded with the GitHub repository, it should work as-is.

Packages imported in the next code block can be installed from CRAN as needed.

```{r}
setwd('.')
library(rio)
library(dplyr)
library(psych)
```
### About the Data

[The article] includes two different analyses of RAMP data. Both use search engine performance data about RAMP IR harvested from the Google Search Console (GSC) API, though the data used for each analysis are different. For detailed information about how RAMP data are harvested, processed, and exported to CSV format, please see documentation included with the published subset of RAMP data:

> Wheeler, Jonathan et al. (2020), RAMP data subset, January 1 through May 31, 2019, v6, University of New Mexico, Dataset, <https://doi.org/10.5061/dryad.fbg79cnr0>

The RAMP data published as cited above are the same as the data that were used for the analyses in the article. For the reported analyses, the data were further augmented with some additional data about indvidual RAMP IR and global north-south designations of countries represented in the search engine performance data harvested from GSC. All relevant data aggregation and analysis scripts are included, with documentation, in the the GitHub repository that includes this R Markdown file.

Section headings provided here are the same as used in the article. Where code blocks output results used in the article, those code blocks are labeled with the corresponding figure or table number.

### Page Click Analysis

This analysis uses information about RAMP IR that was manually gathered in May and June 2019. For each IR included in the study, this information is cross referenced with aggregated page-click data to provide summary statistics about IR search engine performance. There are limitations to the conclusions that may be drawn from this summary analysis - please see the article for more information. **In particular, the authors of this study strongly discourage qualitative assessments of any and all IR included in this study. The results provided by this analysis, as reported, should not be taken as an assessment of the quality of IR providers, platforms, and/or content.**

The summary statistics used for the reported analysis were generated on January 9, 2020. The output is included in the GitHub repository and is referenced in the corresponding import path below. Note that the script and data needed to reproduce those same summary stats are included in this GitHub repository. Interested parties are invited to redo the aggregation and run this notebook against the new output. If the same data are used, any discrepancies with published results should be brought to the authors' attention.

```{r}
## Read the csv file with descriptive statistics for RAMP IR.
## Note the filename incluces a date, which may need to be updated.

## The file referenced in the next line was used for the reported 
## analysis and is included in the GitHub repo. It is not necessary
## to change the path unless you want to run against more recently
## aggregated data.
IR <- import("../results/RAMP_summary_stats_20200109.csv")
str(IR)
```
```{r, fig.cap="Table 1"}
## Items in repository
## 35 IR were included in the study, so the output of the length() command should be 35.
## The data frame length and the summary data are included in Table 1.
length(IR$ir)
summary(IR$countItems)
```
```{r, fig.cap="Table 2"}
## Item counts summarized by platform.
IR%>% 
  group_by(normIrPlat)%>% 
  summarise(sum = sum(countItems))%>%
  arrange(desc(sum))
IR$Platform <- factor(IR$normIrPlat, levels = c("DSpace", "Digital Commons", "EPrints", "Fedora"))
describeBy(IR$countItems, IR$Platform)
```
```{r, fig.cap="Table 3"}
## Item counts summarized by country where the IR are located.
IR%>% 
  group_by(irCountry)%>% 
  summarise(sum = sum(countItems))%>%
  arrange(desc(sum))
IR$Country <- factor(IR$irCountry, levels = c("USA", "Australia", "UK", "Canada", "Sweden", "New Zealand", "South Africa"))
describeBy(IR$countItems, IR$irCountry)

```

```{r}
dat1 <- import("../ramp_data/2019-01_RAMP_subset_country-device-info.csv")
dat2 <- import("../ramp_data/2019-02_RAMP_subset_country-device-info.csv")
dat3 <- import("../ramp_data/2019-03_RAMP_subset_country-device-info.csv")
dat4 <- import("../ramp_data/2019-04_RAMP_subset_country-device-info.csv")
dat5 <- import("../ramp_data/2019-05_RAMP_subset_country-device-info.csv")
str(dat1)
```
```{r}
str(dat2)
```
```{r}
str(dat3)
```
```{r}
str(dat4)
```
```{r}
str(dat5)
```
```{r}
dat1 <- dat1[, c(-2, -5, -6)]
dat2 <- dat2[, c(-2, -5, -6)]
dat3 <- dat3[, c(-2, -5, -6)]
dat4 <- dat4[, c(-2, -5, -6)]
dat5 <- dat5[, c(-2, -5, -6)]
country_device <- rbind(dat1, dat2)
country_device <- rbind(country_device, dat3)
country_device <- rbind(country_device, dat4)
country_device <- rbind(country_device, dat5)
length(unique(country_device$index))
```
```{r}
country_device <- country_device[, c(-5)]
```
```{r}
length(unique(country_device$country))
```

The next two code blocks are for table 11 and figure 10.

```{r}
country_device %>% 
  select(clicks, device) %>% 
  group_by(device) %>% 
  summarise(clicks = sum(clicks)) %>% 
  arrange(desc(clicks)) %>% 
  mutate(percent = clicks/sum(clicks)*100)
```
Here's some code that reproduces the data we have in table 11 now:

```{r}
country_device %>% 
  select(clicks, device) %>% 
  group_by(device) %>% 
  summarise(device_row_count = sum(!is.na(clicks))) %>% 
  arrange(desc(device_row_count)) %>% 
  mutate(percent = device_row_count/4333430*100)
```

```{r}
dat6 <- import('../ir_data/North_South.csv')
head(dat6)
```
```{r}
length(dat6$Countryabbre)
```
```{r}
dat6$Countryabbre <- tolower(dat6$Countryabbre)
head(dat6)
```
```{r}
country_device_n <- merge(country_device, dat6, by.x = "country", by.y = "Countryabbre")
length(unique(country_device_n$country))
```
```{r}
dat7 <- unique(country_device$country)
dat8 <- unique(dat6$Countryabbre)
dat7[!(dat7 %in% dat8)]
```
```{r}
dat8[!(dat8 %in% dat7)]
```
```{r}
write.csv(country_device_n, file = '../ir_data/country_device_n.csv')
```
```{r}
describeBy(country_device_n$clicks, country_device_n$device)
```

```{r}
describeBy(country_device_n$position, country_device_n$device)
```
```{r}
country_device_n %>% select(clicks, country) %>% 
  group_by(country) %>% 
  summarise(clicks = sum(clicks)) %>% 
  arrange(desc(clicks)) %>% 
  head(5)
```


```{r}
country_device_n$Location <- as.factor(country_device_n$Location)
```
```{r}
country_device_n %>% 
  select(clicks, Location) %>% 
  group_by(Location) %>% 
  summarise(clicks = sum(clicks)) %>% 
  arrange(desc(clicks)) %>% 
  mutate(percent = clicks/sum(clicks)*100)
```
```{r}
country_device_n%>%
  select(clicks, device, Location)%>%
  group_by(Location, device)%>%
  summarise(clicks = sum(clicks))%>%
  arrange(desc(clicks))%>%
  mutate(percent = clicks/sum(clicks)*100)
```
```{r}
mean(country_device_n$clicks)
```
```{r}
var(country_device_n$clicks)
```
```{r}
range(country_device_n$clicks)
```
```{r}
mod <- glm(clicks~position*device, data = country_device_n, family = c("quasipoisson"))
summary(mod)
```
```{r}
round(cbind(exp(coef(mod)),
            exp(confint(mod))),3)
```